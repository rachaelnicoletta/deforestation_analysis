{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GGS 416 - Final Individual Project - Deforestation Analysis ###\n",
    "# Rachael Nicoletta \n",
    "# Due 11/29/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60598a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentinelsat in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2.28.1)\n",
      "Requirement already satisfied: geomet in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (0.3.0)\n",
      "Requirement already satisfied: click>=7.1 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (7.1.2)\n",
      "Requirement already satisfied: tqdm>=4.58 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (4.64.1)\n",
      "Requirement already satisfied: geojson>=2 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2.5.0)\n",
      "Requirement already satisfied: html2text in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from sentinelsat) (2020.1.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from tqdm>=4.58->sentinelsat) (0.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from geomet->sentinelsat) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\racha\\anaconda3\\envs\\sia\\lib\\site-packages (from requests->sentinelsat) (3.3)\n"
     ]
    }
   ],
   "source": [
    "### Useful Imports and Globals ###\n",
    "import os\n",
    "\n",
    "# Sentinel API specific. Imports sys and installs Sentinel API package in current virtual environment\n",
    "import sys\n",
    "!{sys.executable} -m pip install sentinelsat\n",
    "\n",
    "# Imports classes to connect to Copernicus Open Access Hub (sentinelsat) and\n",
    "# other relevant geojson packages.\n",
    "import sentinelsat\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "# Working with data\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For unzipping zipped packages\n",
    "import zipfile\n",
    "\n",
    "# For traversing directories and getting file names and paths\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Plotting\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Several of our functions change our current working directory but lots of other functions require the file\n",
    "# path to our base directory. This creates a variable of the home directory from the start for future use.\n",
    "home_directory = os.getcwd()\n",
    "#print(home_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e61b097e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cloudcoverpercentage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 89>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_metadata_df)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Sorts the metadata by cloud coverage (lowest up top)\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m image_metadata_df_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mimage_metadata_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcloudcoverpercentage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Exports to a csv file\u001b[39;00m\n\u001b[0;32m     92\u001b[0m image_metadata_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\core\\frame.py:6319\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[0;32m   6316\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6318\u001b[0m     by \u001b[38;5;241m=\u001b[39m by[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 6319\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6321\u001b[0m     \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6324\u001b[0m         \u001b[38;5;66;03m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\pandas\\core\\generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cloudcoverpercentage'"
     ]
    }
   ],
   "source": [
    "### Rachael (but most of it adapted from lecture notes) - Downloading Sentinel-2 Imagery ###\n",
    "\n",
    "# Creates an object containing our Sentinel API key data linked with my account.\n",
    "api = SentinelAPI(\n",
    "    'rnicole', \n",
    "    'Ranvegan_0421',\n",
    "    'https://apihub.copernicus.eu/apihub'\n",
    ")\n",
    "\n",
    "# Defining the GeoJSON type as a single geometry, a polygon, and its boundaries\n",
    "footprint = {\n",
    "  \"type\": \"Feature\",\n",
    "  \"properties\": {},\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Point\",\n",
    "    #\"coordinates\": [-17.22692, -60.55876],\n",
    "    #\"coordinates\": [-7.90866, -54.98014],\n",
    "    \"coordinates\": [-7.96352, -54.75262]\n",
    "  }\n",
    "}\n",
    "footprint = geojson_to_wkt(footprint)\n",
    "\n",
    "# footprint = {\n",
    "#   \"type\": \"Feature\",\n",
    "#   \"properties\": {},\n",
    "#   \"geometry\": {\n",
    "#     \"coordinates\": [[\n",
    "#             [\n",
    "#               -56.94201589791588,\n",
    "#               -13.21282120444431\n",
    "#             ],\n",
    "#             [\n",
    "#               -56.59685360146098,\n",
    "#               -13.21282120444431\n",
    "#             ],\n",
    "#             [\n",
    "#               -56.59685360146098,\n",
    "#               -12.901532851611265\n",
    "#             ],\n",
    "#             [\n",
    "#               -56.94201589791588,\n",
    "#               -12.901532851611265\n",
    "#             ],\n",
    "#             [\n",
    "#               -56.94201589791588,\n",
    "#               -13.21282120444431\n",
    "#             ]\n",
    "#           ]\n",
    "#         ],\n",
    "#         \"type\": \"Polygon\"\n",
    "#   }\n",
    "# }\n",
    "# footprint = geojson_to_wkt(footprint)\n",
    "\n",
    "# Sends an api request to the sentinel server to search for images intersecting\n",
    "# our polygon boundaries and within our specified timeframe and platform (Sentinel-2).\n",
    "# image_metadata = api.query(\n",
    "#     footprint,\n",
    "#     date=('20221001', '20221007'), # September to December 2021\n",
    "#     platformname = 'Sentinel-3',\n",
    "#     filename = 'S3A_SY*',\n",
    "#     #platformname = 'S3A_*',\n",
    "#     #processinglevel = 'Level-1C', # Change to 'Level-2A' for those images\n",
    "#     #processinglevel = 'OL_2_LFR',\n",
    "#     #producttype = 'OL_1_EFR',\n",
    "#     producttype = 'SY_2_VGP___',\n",
    "#     timeliness = 'Non Time Critical',\n",
    "#     cloudcoverpercentage = ('0', '25') # Only pulls data with less than 25% cloud coverage\n",
    "# )\n",
    "\n",
    "image_metadata = api.query(\n",
    "    footprint,\n",
    "    date=('20220801', '20221101'), # September to December 2021\n",
    "    platformname = 'Sentinel-2',\n",
    "    filename = 'S2A*',\n",
    "    #platformname = 'S3A_*',\n",
    "    processinglevel = 'Level-2A', # Change to 'Level-2A' for those images\n",
    "    #processinglevel = 'OL_2_LFR',\n",
    "    #producttype = 'OL_1_EFR',\n",
    "    #producttype = 'SY_2_VGP___',\n",
    "    #timeliness = 'Non Time Critical',\n",
    "    cloudcoverpercentage = ('0', '25') # Only pulls data with less than 25% cloud coverage\n",
    ")\n",
    "\n",
    "image_metadata_df = api.to_dataframe(image_metadata)\n",
    "print(image_metadata_df)\n",
    "\n",
    "# Sorts the metadata by cloud coverage (lowest up top)\n",
    "image_metadata_df_sorted = image_metadata_df.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "\n",
    "# Exports to a csv file\n",
    "image_metadata_df.to_csv(\"image_data.csv\")\n",
    "\n",
    "# Downloads all images from dataframe. \n",
    "# ** Keep commented unless you need to download the images again. **\n",
    "#api.download_all(image_metadata_df_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a75b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unzipping folders (from lecture notes) ###\n",
    "\n",
    "def unzip_files():\n",
    "    # Get a list of all filenames in our directory\n",
    "    all_filenames_in_folder = os.listdir() \n",
    "\n",
    "    # Create an empty list for the filenames we want to unzip\n",
    "    filenames_to_unzip = []\n",
    "\n",
    "    # Loop over filenames and put .zip files in our list\n",
    "    for filename in all_filenames_in_folder:\n",
    "        if filename.endswith('.zip'): # Only let .zip files append \n",
    "            filenames_to_unzip.append(filename)\n",
    "\n",
    "    # Creates a new folder for our unzipped files\n",
    "    folder = 'unzipped'\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder) # Make the folder if it does not exist \n",
    "\n",
    "    for filename in filenames_to_unzip:\n",
    "        # Unzip the zip file and put it in the 'unzipped' folder\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder)\n",
    "\n",
    "        os.remove(filename)\n",
    "        \n",
    "unzip_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bb265cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rachael - Pull the bands we want from data download ###\n",
    "\n",
    "# Some of the findExt() code is adapted from this useful website\n",
    "# https://w3guides.com/tutorial/recursively-searching-for-files-with-specific-extensions-in-a-directory\n",
    "\n",
    "# Collection of the band types we want to grab (all extensions are specifically for Level-1C files)\n",
    "# Blue (B02), Green (B03), Red (B04), NIR (B08) \n",
    "extensions = ['B08_10m.jp2', 'B04_10m.jp2']\n",
    "\n",
    "# Recursively navigates 'unzipped' folder for all images with our chosen bands.\n",
    "# Appends path name of each file found into a list\n",
    "def findExt(folder):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(folder):\n",
    "        for ext in extensions:\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(ext):\n",
    "                    matches.append(os.path.join(root, filename))\n",
    "    return matches\n",
    "\n",
    "# List of filenames and their paths to move\n",
    "files_to_move = findExt(\"unzipped\")\n",
    "#print(files_to_move)\n",
    "\n",
    "# Directory to compile all of the files we find into\n",
    "dest_dir = \"files_collection\"\n",
    "\n",
    "# Copies every file from our list into our 'files_collection' folder\n",
    "for file in files_to_move:\n",
    "    shutil.copy(file,dest_dir)\n",
    "    #print(\"File copied: \" + file)\n",
    "    \n",
    "# IMPORTANT CONSIDERATION: the files are copied in bulk and need to be manually sorted into separate \n",
    "# True Color / RGB / NIR folders for future functions to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03836c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T21LVF_20220829T135721_B04_10m.jp2', 'T21LVF_20220829T135721_B08_10m.jp2', 'T21LVF_20220908T140101_B04_10m.jp2', 'T21LVF_20220908T140101_B08_10m.jp2', 'T21LVF_20220918T135711_B04_10m.jp2', 'T21LVF_20220918T135711_B08_10m.jp2', 'T21LVF_20220928T135711_B04_10m.jp2', 'T21LVF_20220928T135711_B08_10m.jp2', 'T21LVF_20221008T135711_B04_10m.jp2', 'T21LVF_20221008T135711_B08_10m.jp2', 'T21LWF_20220908T140101_B04_10m.jp2', 'T21LWF_20220908T140101_B08_10m.jp2', 'T21LWF_20220918T135711_B04_10m.jp2', 'T21LWF_20220918T135711_B08_10m.jp2', 'T21LWF_20221008T135711_B04_10m.jp2', 'T21LWF_20221008T135711_B08_10m.jp2']\n",
      "files_collection/T21LVF_20220829T135721_B04_10m.jp2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input shapes do not overlap raster.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWindowError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\mask.py:80\u001b[0m, in \u001b[0;36mraster_geometry_mask\u001b[1;34m(dataset, shapes, all_touched, invert, crop, pad, pad_width)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry_window\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WindowError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If shapes do not overlap raster, raise Exception or UserWarning\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# depending on value of crop\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\features.py:467\u001b[0m, in \u001b[0;36mgeometry_window\u001b[1;34m(dataset, shapes, pad_x, pad_y, north_up, rotated, pixel_precision, boundless)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m boundless:\n\u001b[1;32m--> 467\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mwindow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m window\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\windows.py:754\u001b[0m, in \u001b[0;36mWindow.intersection\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;124;03m\"\"\"Return the intersection of this window and another\u001b[39;00m\n\u001b[0;32m    743\u001b[0m \n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03mWindow\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\windows.py:113\u001b[0m, in \u001b[0;36miter_args.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Iterable):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\windows.py:216\u001b[0m, in \u001b[0;36mintersection\u001b[1;34m(*windows)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m intersect(windows):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WindowError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindows do not intersect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    218\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack([toranges(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m windows])\n",
      "\u001b[1;31mWindowError\u001b[0m: windows do not intersect",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 119>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles_collection/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m file\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[1;32m--> 122\u001b[0m \u001b[43mclip_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_of_interest\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mclip_raster\u001b[1;34m(image_file, mask_bounds)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Applies the rasterio mask by specifying the function needs to crop (via crop=True)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(image_file) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m---> 80\u001b[0m     clipped, transform \u001b[38;5;241m=\u001b[39m \u001b[43mmask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_geojson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Copies the metadata from the original ratserio object\u001b[39;00m\n\u001b[0;32m     83\u001b[0m meta \u001b[38;5;241m=\u001b[39m raster_image\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\mask.py:178\u001b[0m, in \u001b[0;36mmask\u001b[1;34m(dataset, shapes, all_touched, invert, nodata, filled, crop, pad, pad_width, indexes)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m         nodata \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 178\u001b[0m shape_mask, transform, window \u001b[38;5;241m=\u001b[39m \u001b[43mraster_geometry_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_touched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_touched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     out_shape \u001b[38;5;241m=\u001b[39m (dataset\u001b[38;5;241m.\u001b[39mcount, ) \u001b[38;5;241m+\u001b[39m shape_mask\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sia\\lib\\site-packages\\rasterio\\mask.py:86\u001b[0m, in \u001b[0;36mraster_geometry_mask\u001b[1;34m(dataset, shapes, all_touched, invert, crop, pad, pad_width)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WindowError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If shapes do not overlap raster, raise Exception or UserWarning\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# depending on value of crop\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m crop:\n\u001b[1;32m---> 86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput shapes do not overlap raster.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshapes are outside bounds of raster. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAre they in different coordinate reference systems?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Input shapes do not overlap raster."
     ]
    }
   ],
   "source": [
    "### Daniel's Clipping Function (Need to update locations for my directory) ###\n",
    "\n",
    "# TCI_input=r\"{}\\files_collection\\Level-1C\\TCI\".format(home_directory)\n",
    "# NIR_input=r\"{}\\files_collection\\Level-1C\\NIR\".format(home_directory)\n",
    "\n",
    "# def clip_function(directory,xmin,ymin,xmax,ymax):\n",
    "#     #Setting the directory\n",
    "#     dir=directory\n",
    "#     os.chdir(dir)\n",
    "#     #Collecting the list of .jp2 files\n",
    "#     for file in os.listdir():\n",
    "#         if file.endswith(\".jp2\"):\n",
    "#             print(f\"I am opening {file}.\")\n",
    "#             image_file=file\n",
    "#             my_raster_image=rasterio.open(file)\n",
    "\n",
    "#             #specifying clipping box\n",
    "#             my_geojson = [{\n",
    "#                 \"type\": \"Polygon\",\n",
    "#                 \"coordinates\": [\n",
    "#                     [\n",
    "#                         [xmin, ymin],\n",
    "#                         [xmax, ymin],\n",
    "#                         [xmax, ymax],\n",
    "#                         [xmin, ymax],\n",
    "#                         [xmin, ymin]\n",
    "#                     ],\n",
    "#                 ]\n",
    "#             }]\n",
    "\n",
    "#             with rasterio.open(image_file) as img:\n",
    "#                 clipped, transform = mask(img, my_geojson, crop=True)\n",
    "\n",
    "#                 #Grabbing metadata from unclipped image\n",
    "#                 meta=my_raster_image.meta.copy()\n",
    "\n",
    "#                 #Updating the metadata, and providing the new clipped boundaries\n",
    "#                 meta.update(\n",
    "#                     {\n",
    "\n",
    "#                         \"transform\": transform,\n",
    "#                         \"height\": clipped.shape[1],\n",
    "#                         \"width\": clipped.shape[2]\n",
    "#                     }\n",
    "#                 )\n",
    "\n",
    "#                 # Writing clipped image to GeoTIF\n",
    "#                 with rasterio.open(f'{image_file}_clipped.TIF', 'w', **meta) as my_writer_object:\n",
    "#                     my_writer_object.write(clipped)\n",
    "\n",
    "#                 print(f\"Done clipping {image_file}!\")\n",
    "\n",
    "# clip_function(TCI_input,-56.94201589791588,-13.21282120444431,-56.59685360146098,-12.901532851611265)\n",
    "# clip_function(NIR_input,-56.94201589791588,-13.21282120444431,-56.59685360146098,-12.901532851611265)\n",
    "\n",
    "def clip_raster(image_file, mask_bounds):\n",
    "    \n",
    "    # Define a rasterio object so we can use rasterio functions\n",
    "    raster_image = rasterio.open(image_file)\n",
    "    \n",
    "    # Get mix and max x, y bounds from tuple\n",
    "    xmin, ymin, xmax, ymax = mask_bounds\n",
    "\n",
    "    # Defines the geometry type of our AOI (a polygon since its square)\n",
    "    mask_geojson = [{\n",
    "        \"type\": \"Polygon\", \n",
    "        \"coordinates\": [ \n",
    "          [\n",
    "            [xmin, ymin],\n",
    "            [xmax, ymin],\n",
    "            [xmax, ymax],\n",
    "            [xmin, ymax],\n",
    "            [xmin, ymin]\n",
    "          ],\n",
    "        ]\n",
    "      }]\n",
    "\n",
    "    # Applies the rasterio mask by specifying the function needs to crop (via crop=True)\n",
    "    with rasterio.open(image_file) as img:\n",
    "        clipped, transform = mask(img, mask_geojson, crop=True)\n",
    "    \n",
    "    # Copies the metadata from the original ratserio object\n",
    "    meta = raster_image.meta.copy()\n",
    "\n",
    "    # Updates the metadata with the new clipped boundaries and transform value\n",
    "    meta.update(\n",
    "        {\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"transform\": transform,\n",
    "            \"height\":clipped.shape[1],\n",
    "            \"width\":clipped.shape[2]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Write new image to a GeoTIFF and includes the new meta data values\n",
    "    clipped_file = image_file[0:-4] + \"_clipped.tif\"\n",
    "    with rasterio.open(clipped_file, 'w', **meta) as my_writer_object:\n",
    "        my_writer_object.write(clipped)\n",
    "        print(my_writer_object.profile)\n",
    "        \n",
    "    print('Clipping complete. New file name: ' + clipped_file)\n",
    "    \n",
    "    # Closes the rasterio object\n",
    "    raster_image.close()\n",
    "\n",
    "# Specify filename variable for Planet image\n",
    "image_file = \"psp2_20221014_154622_06_2474_3B_AnalyticMS_1.tif\"\n",
    "\n",
    "# The Area of Interest (AOI) - obtained from zooming in on overlapped, unprojected images in QGIS\n",
    "# variables are sorted by: xmin, ymin, xmax, ymax\n",
    "area_of_interest = (-56.94201589791588,-13.21282120444431,-56.59685360146098,-12.901532851611265) \n",
    "\n",
    "# Performs the clipping process for the planet using the area of interest min \n",
    "# and max x,y values\n",
    "\n",
    "files = os.listdir('files_collection')\n",
    "print(files)\n",
    "\n",
    "for file in files:\n",
    "    path = 'files_collection/' + file\n",
    "    print(path)\n",
    "    clip_raster(path, area_of_interest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bafaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daniel's Average Weekly Temp Code ###\n",
    "\n",
    "# Creates a dataframe with the average weekly temperatures. NOTE: the data must be downloaded first\n",
    "# from the NOAA website. We used Mount Mansfield, VT US temperature data.\n",
    "\n",
    "#Creating function\n",
    "def average_weekly_temp(file_path,output_folder_dir): #Input parameter is the file path of the temperature data .csv file\n",
    "    \n",
    "    #Creating counting varibles and empty lists to store data \n",
    "    day=0\n",
    "    week=0\n",
    "    date_list=[]\n",
    "    week_list=[]\n",
    "    average_temp_list=[]\n",
    "    average_temp_c_list=[]\n",
    "    table=pd.read_csv(file_path) # reading in the .csv\n",
    "    print(table) #displaying the table\n",
    "    \n",
    "    date_column=table[\"DATE\"] #saving the data column in the temperature csv \n",
    "    \n",
    "    #Looping through all of the dates in the date column and appending them to the empty date list\n",
    "    for date in date_column: \n",
    "        date_list.append(date)\n",
    "    \n",
    "    #The temperature .csv contains daily maximum temperatures and not weekly averages. \n",
    "    #The following code calculates weekly average temperatures from daily average temperatures\n",
    "    \n",
    "    temp_column=table[\"TMAX\"] #Saving the daily maximum temperatures column as a variable\n",
    "    \n",
    "    #Creating counting variables\n",
    "    day_counter=0\n",
    "    total_temp=0\n",
    "    \n",
    "    #Setting up the loop to calculate the average temperature for all 13 weeks\n",
    "    for temp in temp_column:\n",
    "        day_counter+=1\n",
    "        print(f\"We are on day:{day_counter}.\")\n",
    "        total_temp+=temp\n",
    "        \n",
    "        if day_counter%7==0:\n",
    "            week+=1\n",
    "            week_list.append(week)\n",
    "            temp_average=total_temp/7\n",
    "            average_temp_c=(temp_average-32)*5/9 #Converting each average temp in farenheight to celcius \n",
    "            average_temp_list.append(temp_average) #Appending each week's temp average to a list of average temperatures\n",
    "            average_temp_c_list.append(average_temp_c)\n",
    "            print(f\"The average temperature of week {week} is {temp_average}.\")\n",
    "            total_temp=0 #Resetting this variable back to zero \n",
    "            \n",
    "            #Assigning each column of the new dataframe to a column variable\n",
    "        column1=week_list\n",
    "        column2=average_temp_list\n",
    "        column3=average_temp_c_list\n",
    "    \n",
    "    #Simply displaying all of the lists containing data for the columns\n",
    "    print(week_list,average_temp_list,average_temp_c_list) \n",
    "    \n",
    "    #Creating the new dataframe\n",
    "    dataframe = pd.DataFrame(list(zip(column1, column2, column3)),\n",
    "                             columns=['week', 'average_temp', \"average_temp_c\"])\n",
    "    \n",
    "    os.chdir(output_folder_dir) #Changing the directory so the new csv can be exported here \n",
    "    print(os.getcwd()) #Confirming the directory was changed\n",
    "    \n",
    "    dataframe.to_csv(r\"average_weekly_temp_values.csv\") #Exporting the new csv file\n",
    "    \n",
    "\n",
    "#Running the function with the input and output directory\n",
    "average_weekly_temp(r\"D:\\GGS 416 Group Project\\temp_data_sep_to_dec.csv\",r\"D:\\GGS 416 Group Project\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b713ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daniel’s Image Processing and CSV generator code made on 10/31/2022 ###\n",
    "\n",
    "# Gets the average red, green, blue, and NIR pixel values from each image and appends them\n",
    "# to a table for exporting as a csv.\n",
    "def table_creator(directory_1,directory_2):\n",
    "    #Creating empty lists to store the average values\n",
    "    file_names=[]\n",
    "    blue_values=[]\n",
    "    green_values=[]\n",
    "    red_values=[]\n",
    "    nir_values=[]\n",
    "    #setting and changing the directory\n",
    "    file_location_1=directory_1\n",
    "    file_location_2=directory_2\n",
    "    os.chdir(file_location_1)\n",
    "    #reading the pixel values as a numpy array by band\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".TIF\"):\n",
    "            #Appending to the lists\n",
    "            opened_image=rasterio.open(file)\n",
    "            blue=opened_image.read(1)\n",
    "            green=opened_image.read(2)\n",
    "            red= opened_image.read(3)\n",
    "            average_blue=np.average(blue)\n",
    "            average_green=np.average(green)\n",
    "            average_red=np.average(red)\n",
    "            file_name=file\n",
    "            file_names.append(file)\n",
    "            blue_values.append(average_blue)\n",
    "            green_values.append(average_green)\n",
    "            red_values.append(average_red)\n",
    "    os.chdir(file_location_2)\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".TIF\"):\n",
    "        #Appending to the lists\n",
    "            opened_image=rasterio.open(file)\n",
    "            nir=opened_image.read(1)\n",
    "            average_nir=np.average(nir)\n",
    "            nir_values.append(average_nir)\n",
    "        \n",
    "    #Printing the generated lists\n",
    "    print(f\"Here is the file name list {file_names}.\")\n",
    "    print(f\"Here is the blue list {blue_values}.\")\n",
    "    print(f\"Here is the green list {green_values}.\")\n",
    "    print(f\"Here is the red list {red_values}.\")\n",
    "    print(f\"Here is the nir list {nir_values}.\")\n",
    "    #Assigning each list to a column of the dataframe\n",
    "    column1=file_names\n",
    "    column2=blue_values\n",
    "    column3=green_values\n",
    "    column4=red_values\n",
    "    column5=nir_values\n",
    "    #Creating the dataframe\n",
    "    data = pd.DataFrame(list(zip(column1, column2,column3,column4,column5)),\n",
    "                      columns=['image', 'average_blue',\"average_green\",\"average_red\",\"average_nir\"])\n",
    "    return data\n",
    "\n",
    "#Running the function\n",
    "average_rgb_data = table_creator(r\"{}\\files_collection\\Level-1C\\TCI\".format(home_directory), \n",
    "                                 r\"{}\\files_collection\\Level-1C\\NIR\".format(home_directory))\n",
    "\n",
    "### Rachael - Add Dates Field to Dataset Using Image Filename Content ###\n",
    "\n",
    "def add_dates(data_frame):\n",
    "    # Contains dates to be added to the dataframe.\n",
    "    image_dates = []\n",
    "\n",
    "    # Iterates through each file, creates substring of dates using file name, and adds to list. These will be\n",
    "    # used along the x-axis in our plots.\n",
    "    for row in data_frame.iterrows():\n",
    "\n",
    "        file = row[1]['image']\n",
    "        date = file[11:13] + \"/\" + file[13:15] # Add this if you want to include the year: + \"/\" + file[7:11]\n",
    "        image_dates.append(date)\n",
    "\n",
    "    # Assign new column to existing dataframe\n",
    "    data_frame = data_frame.assign(date = image_dates)\n",
    "\n",
    "    #Exporting the dataframe\n",
    "    data_frame.to_csv(r\"{}\\average_reflectance_values.csv\".format(home_directory))\n",
    "    \n",
    "add_dates(average_rgb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daniel - Standardize Reflectance Values by Converting to Percentages ###\n",
    "\n",
    "# Due to the True Color (RGB) bands be 8 bit and the NIR band being 16 bit, we need to standardize our reflectance\n",
    "# values so we can fairly compare them. This function converts each band value to percentage and assigns them to the\n",
    "# current reflectance values datasets in new columns.\n",
    "def reflectance_to_percentage(table_path):\n",
    "    blue_percentage_list=[]\n",
    "    green_percentage_list=[]\n",
    "    red_percentage_list=[]\n",
    "    nir_percentage_list=[]\n",
    "    table=pd.read_csv(table_path)\n",
    "    for value in table[\"average_blue\"]:\n",
    "        percentage=value/255*100\n",
    "        blue_percentage_list.append(percentage)\n",
    "    for value in table[\"average_green\"]:\n",
    "        percentage=value/255*100\n",
    "        green_percentage_list.append(percentage)\n",
    "    for value in table[\"average_red\"]:\n",
    "        percentage=value/255*100\n",
    "        red_percentage_list.append(percentage)\n",
    "    for value in table[\"average_nir\"]:\n",
    "        percentage=value/65536*100\n",
    "        nir_percentage_list.append(percentage)\n",
    "    print(f\"Blue percentage list: {blue_percentage_list}.\")\n",
    "    print(f\"Green percentage list: {green_percentage_list}.\")\n",
    "    print(f\"Blue percentage list: {red_percentage_list}.\")\n",
    "    print(f\"Nir percentage list: {nir_percentage_list}.\")\n",
    "    column_headers = ['avg_blue_reflectance_percentage', 'avg_green_reflectance_percentage', \n",
    "                      'avg_red_reflectance_percentage', 'avg_nir_reflectance_percentage']\n",
    "    table2=table.assign(average_blue_percentage=blue_percentage_list,average_green_percentage=green_percentage_list,\n",
    "                        average_red_percentage=red_percentage_list,average_nir_percentage=nir_percentage_list)\n",
    "    export_dir=home_directory\n",
    "    os.chdir(export_dir)\n",
    "    table2.to_csv(r\"{}\\average_reflectance_values_with_percentage.csv\".format(home_directory))\n",
    "\n",
    "\n",
    "reflectance_to_percentage(r\"{}\\average_reflectance_values.csv\".format(home_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b742b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rachael - Create RGB Histograms (Pandas and Matplot) ###\n",
    "\n",
    "# Reads in our file\n",
    "average_rgb_data = pd.read_csv('average_reflectance_values_with_percentage.csv')\n",
    "\n",
    "# Separates our bands into rgb and nir arrays of values\n",
    "blue = average_rgb_data['average_blue_percentage']\n",
    "green = average_rgb_data['average_green_percentage']\n",
    "red = average_rgb_data['average_red_percentage']\n",
    "nir = average_rgb_data['average_nir_percentage']\n",
    "\n",
    "# The number of histogram bins\n",
    "bin_number = 10\n",
    "\n",
    "# Create just a figure and only one subplot\n",
    "fig, (ax1, ax2) = plt.subplots(2,2, sharey=True)\n",
    "\n",
    "# Sets the number of ticks for the y-axis\n",
    "plt.yticks([2, 4, 6, 8])\n",
    "\n",
    "# Sets default background color (outside the plot area) to white\n",
    "# *Keep this* otherwise it will default to grey and is hard to read\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Sets the colors and bin count of each plot\n",
    "ax1[0].hist(blue, color='blue', bins=bin_number, range=[10, 60])\n",
    "ax1[1].hist(green, color='green', bins=bin_number, range=[10, 60])\n",
    "ax2[0].hist(red, color='red', bins=bin_number, range=[10, 60])\n",
    "ax2[1].hist(nir, color='gray', bins=bin_number, range=[2, 6])\n",
    "\n",
    "# States the title and axis labels for the plots\n",
    "ax1[0].set_title('Blue Pixel Values')\n",
    "ax1[1].set_title('Green Pixel Values')\n",
    "ax2[0].set_title('Red Pixel Values')\n",
    "ax2[1].set_title('NIR Pixel Values')\n",
    "ax1[0].set_ylabel('Frequency')\n",
    "ax2[0].set_ylabel('Frequency')\n",
    "ax2[0].set_xlabel('% Average Pixel Values')\n",
    "ax2[1].set_xlabel('% Average Pixel Values')\n",
    "\n",
    "# Adds an overall title to the plot. The y argument moves the \n",
    "# title higher, so we don't have overlapping text.\n",
    "plt.suptitle('Histogram Panel-Plot by Band', y=1.05)  \n",
    "\n",
    "# This makes sure we have sufficient space between our plots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Export the final plot into a .png file with padding!\n",
    "fig.savefig(r\"{}\\histograms.png\".format(home_directory), dpi=200, bbox_inches='tight', pad_inches=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada71e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rachael - Create Time Series Histograms for % Average Pixel Values and Weekly Temperatures ###\n",
    "\n",
    "# NOTE: the average weekly temperature values need to be added to the average_reflectance_values.csv\n",
    "# file before this function can work (or at least create the temperature time series plot).\n",
    "#\n",
    "# Also, the 'date' column is formatted in 'month/day' format for the x-axis in the plots.\n",
    "\n",
    "# Reads in data from .csv file            \n",
    "average_reflectance_values = pd.read_csv(r\"{}\\average_reflectance_values_with_percentage.csv\".format(home_directory))\n",
    "\n",
    "# Sorts data by ascending date (September to December)\n",
    "average_reflectance_values_sorted = average_reflectance_values.sort_values(by='date')\n",
    "\n",
    "# Example\n",
    "data = average_reflectance_values.set_index('date')\n",
    "\n",
    "# Begin creating the RGB Time Series Plot\n",
    "# Create RGB subplot and unpack the output array\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Sets default background color (outside the plot area) to white\n",
    "# *Keep this* otherwise it will default to grey and is hard to read\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Add the line data we want to plot, with labels and bespoke markers\n",
    "plt.plot(data[\"average_blue_percentage\"], label='Blue', color='blue')\n",
    "plt.plot(data[\"average_green_percentage\"], label='Green', color='green')\n",
    "plt.plot(data[\"average_red_percentage\"], label='Red', color='red')\n",
    "plt.plot(data[\"average_nir_percentage\"], label='NIR', color='gray')\n",
    "plt.legend()\n",
    "\n",
    "# Add the axes labels and limits\n",
    "plt.xlabel(\"Date\", fontname=\"Verdana\", fontsize=12)\n",
    "plt.ylabel(\"% Average Pixel Values\", fontname=\"Verdana\", fontsize=12)\n",
    "\n",
    "# Add the main plot title\n",
    "plt.title(\"Fall 2021 Time Series Plot\\nof RGB and NIR Values\", fontname=\"Verdana\", fontsize=18)\n",
    "\n",
    "#set parameters for tick labels\n",
    "plt.tick_params(axis='x', which='major', labelsize=7)\n",
    "# This makes sure we have sufficient space between our plots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Now export the final plot!\n",
    "fig.savefig(r\"{}\\rgb_nir_time_series.png\".format(home_directory), dpi=200, \n",
    "            bbox_inches='tight', pad_inches=0.7)\n",
    "\n",
    "\n",
    "# Begin creating the NIR Time Series Plot\n",
    "ax.clear()\n",
    "\n",
    "# Add the line data we want to plot, with labels and bespoke markers\n",
    "plt.plot(data[\"average_nir_percentage\"], label='NIR', color='gray')\n",
    "plt.legend()\n",
    "\n",
    "# Add the axes labels and limits\n",
    "plt.xlabel(\"Date\", fontname=\"Verdana\", fontsize=12)\n",
    "plt.ylabel(\"% Average Pixel Values\", fontname=\"Verdana\", fontsize=12)\n",
    "\n",
    "# Add the main plot title\n",
    "plt.title(\"Fall 2021 Time Series Plot\\nof NIR Values\", fontname=\"Verdana\", fontsize=18)\n",
    "\n",
    "# Now export the final plot!\n",
    "fig.savefig(r\"{}\\nir_time_series.png\".format(home_directory), \n",
    "            dpi=200, bbox_inches='tight', pad_inches=0.7)\n",
    "\n",
    "# Begin creating the Temperature Time Series Plot\n",
    "ax.clear()\n",
    "\n",
    "# Add the line data we want to plot, with labels and bespoke markers\n",
    "plt.plot(data[\"average_temp_f\"], label='Fahrenheit', color='orange')\n",
    "plt.plot(data[\"average_temp_c\"], label='Celsius', color='blue')\n",
    "plt.legend()\n",
    "\n",
    "# Add the axes labels and limits\n",
    "plt.xlabel(\"Date\", fontname=\"Verdana\", fontsize=12)\n",
    "plt.ylabel(\"Average Temperature Values\", fontname=\"Verdana\", fontsize=12)\n",
    "\n",
    "# Add the main plot title\n",
    "plt.title(\"Fall 2021 Time Series Plot of\\nWeekly Average Temperature Values\", \n",
    "          fontname=\"Verdana\", fontsize=18)\n",
    "\n",
    "# Now export the final plot!\n",
    "fig.savefig(r\"{}\\temperature_time_series.png\".format(home_directory), \n",
    "            dpi=200, bbox_inches='tight', pad_inches=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Daniel - Calculate the Positive and Negative Differences for Red and NIR Bands ###\n",
    "\n",
    "#This code determines when we saw the largest increases / decreases within our average pixel values between images\n",
    "\n",
    "#Setting the directory of the data table\n",
    "os.chdir(home_directory)\n",
    "\n",
    "table = pd.read_csv(r'{}\\average_reflectance_values_with_percentage.csv'.format(home_directory))\n",
    "\n",
    "#Creating empty lists to store differences between images \n",
    "\n",
    "red_pos_diff_list = []\n",
    "\n",
    "red_neg_diff_list=[]\n",
    "\n",
    "nir_pos_diff_list=[]\n",
    "\n",
    "nir_neg_diff_list=[]\n",
    "\n",
    "largest_diff=0\n",
    "\n",
    "#The following loops append the difference values for both positive/negative differneces for red/NIR\n",
    "\n",
    "#Generating list of red positive/negative differences\n",
    "for i in range(1,len(table)):\n",
    "    diff = (table.iloc[i, 10]-table.iloc[i-1,10])\n",
    "    if diff > 0:\n",
    "        red_pos_diff_list.append(diff)\n",
    "    if diff < 0:\n",
    "        red_neg_diff_list.append(diff)\n",
    "\n",
    "#Generating list of NIR positive/negative differences\n",
    "for i in range(1,len(table)):\n",
    "    diff = (table.iloc[i, 11]-table.iloc[i-1,11])\n",
    "    if diff > 0:\n",
    "        nir_pos_diff_list.append(diff)\n",
    "    if diff < 0:\n",
    "        nir_neg_diff_list.append(diff)\n",
    "\n",
    "#Displaying difference lists        \n",
    "print(red_pos_diff_list)\n",
    "\n",
    "print(red_neg_diff_list)\n",
    "\n",
    "print(nir_pos_diff_list)\n",
    "\n",
    "print(nir_neg_diff_list)\n",
    "\n",
    "#The following code determines the greatest positive / negative differences alongside the images they occured between\n",
    "\n",
    "#Greatest positive differnece for red\n",
    "greatest_pos_diff=0\n",
    "for i in range(1,len(red_pos_diff_list)):\n",
    "    if red_pos_diff_list[i]>greatest_pos_diff:\n",
    "        greatest_pos_diff=red_pos_diff_list[i]\n",
    "print(f\"The greatest red positive difference was {greatest_pos_diff}.\")\n",
    "\n",
    "#Greatest negative difference for red\n",
    "greatest_neg_diff=0\n",
    "for i in range(1,len(red_neg_diff_list)):\n",
    "    if red_neg_diff_list[i] < greatest_neg_diff:\n",
    "        greatest_neg_diff=red_neg_diff_list[i]\n",
    "print(f\"The greatest red negative difference was {greatest_neg_diff}.\")\n",
    "\n",
    "#Determining what two images the greatest positive red difference was between\n",
    "for i in range(1,len(table)):\n",
    "    if table.iloc[i, 10]-table.iloc[i-1,10]==greatest_pos_diff:\n",
    "        image_a=table.iloc[i-1,2]\n",
    "        image_b=table.iloc[i,2]\n",
    "        print(f\"The largest red positive difference was between image: {image_a} and image: {image_b}.\")\n",
    "\n",
    "\n",
    "#Determining what two images the greatest negative red difference was between\n",
    "for i in range(1,len(table)):\n",
    "    if table.iloc[i, 10]-table.iloc[i-1,10]==greatest_neg_diff:\n",
    "        image_a=table.iloc[i-1,2]\n",
    "        image_b=table.iloc[i,2]\n",
    "        print(f\"The largest red negative difference was between image: {image_a} and image: {image_b}.\")\n",
    "\n",
    "#Determining the greatest positive NIR difference\n",
    "greatest_pos_diff=0\n",
    "for i in range(1,len(nir_pos_diff_list)):\n",
    "    if nir_pos_diff_list[i]>greatest_pos_diff:\n",
    "        greatest_pos_diff=nir_pos_diff_list[i]\n",
    "print(f\"The greatest nir positive difference was {greatest_pos_diff}.\")\n",
    "\n",
    "#Determining the greatest negative NIR differnece\n",
    "greatest_neg_diff=0\n",
    "for i in range(1,len(nir_neg_diff_list)):\n",
    "    if nir_neg_diff_list[i] < greatest_neg_diff:\n",
    "        greatest_neg_diff=nir_neg_diff_list[i]\n",
    "print(f\"The greatest nir negative difference was {greatest_neg_diff}.\")\n",
    "\n",
    "#Determining what two images hte greatest positive NIR difference was between\n",
    "for i in range(1,len(table)):\n",
    "    if table.iloc[i, 11]-table.iloc[i-1,11]==greatest_pos_diff:\n",
    "        image_a=table.iloc[i-1,2]\n",
    "        image_b=table.iloc[i,2]\n",
    "        print(f\"The largest nir positive difference was between image: {image_a} and image: {image_b}.\")\n",
    "\n",
    "#Determinining what two images the greatest negative NIR difference was between\n",
    "for i in range(1,len(table)):\n",
    "    if table.iloc[i, 11]-table.iloc[i-1,11]==greatest_neg_diff:\n",
    "        image_a=table.iloc[i-1,2]\n",
    "        image_b=table.iloc[i,2]\n",
    "        print(f\"The largest nir negative difference was between image: {image_a} and image: {image_b}.\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
